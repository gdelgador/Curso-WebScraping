{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INICIANDO CON [SELENIUM](https://selenium-python.readthedocs.io/getting-started.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium es una <b>herramientas de testeo para el desarrollo de páginas web</b>. La cual es muy útil para estos fines ya que permite:\n",
    "- Automatización web.\n",
    "- Selección de campos mediante nombres ID, XPATH, etc.\n",
    "- Entre otros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium trabaja con diversos navegadores, tambien conocidos como navegadores sin cabecera como <a href=\"https://chromedriver.chromium.org/\">google chrome</a> y <a href=\"https://github.com/mozilla/geckodriver\">firefox.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El uso de selenium es muy simple y puede servir como un buen punto de partida para el desarrollo de extractores web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium puede utilizarse en las versiones Python 2.7 y 3.x. En general, el soporte de Selenium es muy extenso y proporciona enlaces para lenguajes como Java, C #, Ruby, Python, por supuesto, y JavaScript. La documentación oficial de Selenium es excelente y fácil de entender incluso si eres un principiante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Realizar web Scraping con Scrapy es 20 veces más rápido que utilizando Selenium**. Además, Scrapy consume mucha menos memoria y uso de CPU que Selenium.\n",
    "\n",
    "**Selenium solo debe usarse en casos en que la página sobre la que se requiera hacer web scraping tenga un alto contenido en javascript** el cual hace sumamente complicado scrapear mediante scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo Extración con selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from scrapy.selector import Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializando webdriver y página web\n",
    "driver = webdriver.Chrome(\"./drivers/chromedriver.exe\")\n",
    "url=\"https://es.wikipedia.org/wiki/Anexo:Pa%C3%ADses\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium posee un conjunto de elemtos para la realización de extracción de la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = Selector(text = driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecionando tabla\n",
    "table = sel.xpath('//table[@class = \"wikitable plainlinks\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnas\n",
    "columns_name = table.css('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Territorio\n",
      "País reclamante\n",
      "Fecha\n",
      "Límites\n"
     ]
    }
   ],
   "source": [
    "# nombre de columnas\n",
    "for col in table.css('th'):\n",
    "    print(col.xpath('./text()').get().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnas\n",
    "filas = table.css('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []\n",
    "for row in table.css('tr')[1:]:\n",
    "    dicx = {}\n",
    "    territorio = row.css('td')[1].css(' ::text').getall()\n",
    "    pais = row.css('td')[2].css('::text').getall()\n",
    "    year = row.css('td')[3].css('::text').get()\n",
    "    \n",
    "    dicx['territorio'] = \"\".join([cadena.strip() for cadena in territorio])\n",
    "    dicx['pais'] = \"\".join([cadena.strip() for cadena in pais])\n",
    "    dicx['year'] = \"\".join([cadena.strip() for cadena in year])\n",
    "    \n",
    "    lista.append(dicx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'territorio': 'Antártida Argentina(parte de laProvincia de Tierra del Fuego, Antártida e Islas del Atlántico Sur)',\n",
       "  'pais': 'Argentina',\n",
       "  'year': '1942'},\n",
       " {'territorio': 'Territorio Antártico Australiano',\n",
       "  'pais': 'Australia',\n",
       "  'year': '1933'},\n",
       " {'territorio': 'Territorio Chileno Antártico(parte de laProvincia de la Antártica Chilena)',\n",
       "  'pais': 'Chile',\n",
       "  'year': '1940'},\n",
       " {'territorio': 'Tierra Adelia(parte de lasTierras Australes y Antárticas Francesas)',\n",
       "  'pais': 'Francia',\n",
       "  'year': '1924'},\n",
       " {'territorio': 'Dependencia Ross', 'pais': 'Nueva Zelanda', 'year': '1923'},\n",
       " {'territorio': 'Tierra de la Reina Maud', 'pais': 'Noruega', 'year': '1939'},\n",
       " {'territorio': 'Isla Pedro I', 'pais': 'Noruega', 'year': '1929'},\n",
       " {'territorio': 'Territorio Antártico Británico',\n",
       "  'pais': 'Reino Unido',\n",
       "  'year': '1908'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al finalizar cerramos el navegador\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Llenado de Formularios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El llenado de formularios se realizará con selenium de una forma facil a partir del envio de elementos keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# scrapy\n",
    "from scrapy.selector import Selector\n",
    "\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://www.w3schools.com/html/html_forms.asp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"./drivers/chromedriver.exe\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encontrando elemnto a llenar\n",
    "\n",
    "# campo First Name\n",
    "fname = driver.find_element_by_id('fname')\n",
    "fname.clear() # limpiamos texto anterior de formulario\n",
    "fname.send_keys('Gonzalo')\n",
    "\n",
    "# Campo Last Name\n",
    "\n",
    "fname = driver.find_element_by_id('lname')\n",
    "fname.clear()\n",
    "fname.send_keys('Delgado')\n",
    "\n",
    "# Click Sobre Formulario\n",
    "# nos posicionamos sobre el objeto submit y clickeamos\n",
    "driver.find_elements_by_xpath('//div[@class=\"w3-example\"]//form/input')[2].click() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al finalizar cerramos el navegador\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAPY + SELENIUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aprovechar el poder de scrapy para fucionar este con nuetro selenium y brindar un conjunto de facilidades al momento de procesar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relacionados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [How to execute JavaScript with Scrapy?](https://www.scrapingbee.com/blog/scrapy-javascript/)\n",
    "- [splash](https://blog.scrapinghub.com/2015/03/02/handling-javascript-in-scrapy-with-splash)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_scraping]",
   "language": "python",
   "name": "conda-env-python_scraping-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
