{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Scrapy: Temas más avanzados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Scrapy: obteniendo url absoluta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapy viene equipado con la funcion <b>urljoin</b> el cual nos permite unir la <b>url base + url deseada</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://quotes.toscrape.com/'\n",
    "response = requests.get( url )\n",
    "\n",
    "html = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pasando contenido al selector\n",
    "sel = Selector(text = html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo utilizado dentro del proyecto scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/page/2/'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obteniendo siguiente pagina\n",
    "link = sel.css(\"li.next > a::attr(href)\").get()\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obteniendo url_absoluta\n",
    "url_absoluta_libro=response.urljoin(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Scrapy: Realizando Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase Request nos permite ingresar a una nueva página web para continuar con el scrapeo de esta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/scrapy/request.png' width=\"700\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerden revisar la documentación completa en la <a href=https://docs.scrapy.org/en/latest/topics/request-response.html>página oficial<a/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo utilizando dentro del proyecto scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libreria importada dentro del proyecto\n",
    "from scrapy.http import Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forma request básica\n",
    "Request(url_absoluta_libro,callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Scrapy Shell: Fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El shell de scrapy posee la funcion <b>Fetch()</b> la cual nos permite ingresar a una nueva página para de este modo seguir trabajando desde el shell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desde la consola de scrapy shell realizar\n",
    "url=\"https://reddit.com\"\n",
    "fetch(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Scrapy: Navegando entre páginas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchas veces nos encontramos con casos en que se requiere obtener información de la primera página y luego se requiere ir navegando dentro de sus páginas para obtener más datos de ella. Para estos casos se requiere utilizar el método Request que vimos anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para introducirnos en una página adicional sin pasar datos previamente extraidos\n",
    "yield Request(absolute_url, callback=self.parse_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/meta.PNG'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para introducirnos en una página adicional con datos previamente extraidos\n",
    "meta = {'URL': absolute_url, \n",
    "        'Title': title, \n",
    "        'Address':address}\n",
    "\n",
    "yield Request(absolute_url, callback=self.parse_page, meta= meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sobre la nueva funcion, debemos recuperar los valores anteriormente recopilados\n",
    "\n",
    "url = response.meta.get('URL')\n",
    "title = response.meta.get('Title')\n",
    "address = response.meta.get('Address')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Scrapy: Completado Formularios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por medio del metodo <b>FormRequest</b> se puede realizar el login en las páginas web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/scrapy/login.png' width=\"700\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerden revisar la documentación completa en la <a href=https://docs.scrapy.org/en/latest/topics/request-response.html>página oficial<a/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.http import FormRequest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se requieren conocer los parámetros con lo que será necesario loguearse\n",
    "FormRequest('http://quotes.toscrape.com/login',\n",
    "                          formdata={'csrf_token': csrf_token,\n",
    "                                    'username': 'abc',\n",
    "                                    'password': '123'},\n",
    "                          callback=self.parse_after_login)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scrapy: Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo principal del scraping es extraer datos estructurados de fuentes no estructuradas, por lo general, páginas web.\n",
    "Scrapy items, es una especie de colector de datos [link](https://docs.scrapy.org/en/latest/topics/items.html) mucho más ordenado de lo que hemos venido utilizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Scrapy: Piperline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de que un elemento ha sido raspado por una araña, se envía al proceso de elementos que lo procesa a través de varios componentes que se ejecutan secuencialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Scrapy donwload images](https://docs.scrapy.org/en/latest/topics/media-pipeline.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_scraping]",
   "language": "python",
   "name": "conda-env-python_scraping-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
