{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. INICIANDO CON SCRAPY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Creando proyecto Scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza el comando <b>scrapy startproject +nombre_del_proyecto</b> en el anaconda Prompt, tal y como se muestra en la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/scrapy/creando_proyecto.png' width='700' height='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Creando spider en Scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos seguir las instrucciones que se muestran luego de crear el proyecto scrapy, las cuales consistene en:\n",
    "- Cambiar el directorio donde nos ubicamos -> <b> cd nombre_proyecto_scrapy</b>\n",
    "- utilizar el comando <b>scrapy genspider + nombre_spider + url</b>\n",
    "\n",
    "Esto creará una plantilla scrapy a la cual accedemos usando vscode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/scrapy/generando_spider.png' width='700' height='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Ejecutar spider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza el comando <b>scrapy crawl + nombre_plantilla_scrapy</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/scrapy/correr_scrapy.png' width='700' height='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SCRAPY [SHEEL](https://docs.scrapy.org/en/latest/topics/shell.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El shell Scrapy es un shell interactivo donde puede intentar depurar su código de raspado muy rápidamente, sin tener que ejecutar la araña. Está destinado a ser utilizado para probar código de extracción de datos, pero en realidad puede usarlo para probar cualquier tipo de código, ya que también es un shell de Python normal.\n",
    "\n",
    "El shell se usa para probar expresiones XPath o CSS y ver cómo funcionan y qué datos extraen de las páginas web que está intentando raspar. Te permite probar interactivamente tus expresiones mientras escribes tu araña, sin tener que ejecutar la araña para probar cada cambio.\n",
    "\n",
    "Una vez que se familiarice con el caparazón de Scrapy, verá que es una herramienta invaluable para desarrollar y depurar sus arañas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El shell de scrapy posee la funcion <b>Fetch()</b> la cual nos permite ingresar a una nueva página para de este modo seguir trabajando desde el shell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desde la consola de scrapy shell realizar\n",
    "url=\"https://reddit.com\"\n",
    "fetch(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EXPORTANDO ARCHIVOS OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que ya obtenido los datos que requerimos de la página, podemos exportar nuestros datos obtenidos por scrapy de forma sencilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Exportando archivos CSV, JSON, XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forma sencilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizar el comando para Correr Scrapy y adicionar los siguientes comandos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>scrapy crawl nombre_plantilla_scrapy -o archivo_nombre.[csv|json|xml]</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/exportando_archivos/archivo_xml.png' width='700' height='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vamos a la carpeta del proyecto, podremos visualizar la salida de archivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/exportando_archivos/salida_archivos.png' width='700' height='500'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NUESTRO PRIMER PROGRAMA USANDO SCRAPY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el desarrollo del siguiente programa extractor web haremos uso de scrapy donde se darán algunos detalles adicionales sobre el entorno scrapy y su uso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La página a utilizar como primer punto será la siguientes: http://quotes.toscrape.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
