{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Manejo Eficiente de gran volumen de Datos Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los profesionales de la ciencia de datos a menudo se encuentran con conjuntos de datos muy grandes con cientos de dimensiones y millones de observaciones. Hay varias formas de manejar grandes conjuntos de datos. Todos conocemos los sistemas de archivos distribuidos como **Hadoop** y **Spark** para manejar big data mediante la paralelización en varios nodos trabajadores en un clúster. \n",
    "\n",
    "Pero para esta sección, usaremos el atributo pandas **chunksize** o la función **get_chunk()**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obteniendo archivos zip de sitios web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [......................................................................] 160301210 / 160301210"
     ]
    }
   ],
   "source": [
    "# pip install wget\n",
    "import wget\n",
    "# descargando archivo de gran volumen de informacion\n",
    "url ='https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/moviedataset.zip'\n",
    "filename = wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrayendo información en carpeta 'datasets'\n",
    "import zipfile\n",
    "zip = zipfile.ZipFile(filename)\n",
    "zip.extractall('./datasets')\n",
    "zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os -> libreria maneja sistema operativo\n",
    "import os\n",
    "os.remove(filename) # remuevo zipfile\n",
    "os.listdir('./datasets/ml-latest') # analizo contenido descomprimido\n",
    "os.chdir('./datasets/ml-latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file 0 links.csv size 725.77 kb\n",
      "file 1 movies.csv size 1729.811 kb\n",
      "file 2 ratings.csv size 620204.63 kb\n",
      "file 3 README.txt size 8.305 kb\n",
      "file 4 tags.csv size 21094.823 kb\n"
     ]
    }
   ],
   "source": [
    "# analizo contenido de archivo\n",
    "for index, f in enumerate(os.listdir()):\n",
    "    print(f'file {index} {f} size {(os.path.getsize(f)/1000)} kb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # linux\n",
    "# !wget -O moviedataset.zip https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/moviedataset.zip\n",
    "# print('unziping ...')\n",
    "# !unzip -o -j moviedataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesando gran volumen de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas carga data en memoria para realizar el procesamiento de datos, ello en casos en que se tenga un gran volumen de datos puede resultar complicado. Para resolver esto podemos usar iteradores en pandas para realizar procesamientos puntuales a la información sin utilizar todos nuestros recursos de memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cual es más común rating de peliculas en el rango de 0.5 a 5.0?\n",
    "2. Cual es el promedio de rating por pelicula ?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo 1: Carga de Gran Volumen de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando librerias\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1204927694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2471</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1204927438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48516</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1204927435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2571</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1436165433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>109487</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1436165496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      169     2.5  1204927694\n",
       "1       1     2471     3.0  1204927438\n",
       "2       1    48516     5.0  1204927435\n",
       "3       2     2571     3.5  1436165433\n",
       "4       2   109487     4.0  1436165496"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rating = pd.read_csv('ratings.csv')\n",
    "df_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22884377, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rating.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El total de consumo de memoria es - 732300192 Bytes.\n"
     ]
    }
   ],
   "source": [
    "ratings_memory = df_rating.memory_usage().sum()\n",
    "\n",
    "# Imprimimos el actual consumo de memoria en la operación\n",
    "print('El total de consumo de memoria es -', ratings_memory,'Bytes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index              128\n",
       "userId       183075016\n",
       "movieId      183075016\n",
       "rating       183075016\n",
       "timestamp    183075016\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finalmente, observamos el consumo de memoria utilizado en cada dimension.\n",
    "df_rating.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo 2: Carga de Gran Volumen de datos con iteradores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una mejor forma de resolver esas preguntas sin utilizar demasida memoria y en tiempo real es utilizando "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_keys = list(df_rating['rating'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.5, 3.0, 5.0, 3.5, 4.0, 2.0, 1.0, 4.5, 1.5, 0.5]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rate_keys = set()\n",
    "for chunk in pd.read_csv('ratings.csv', chunksize=10000):\n",
    "    new = set(chunk['rating'].unique())\n",
    "    rate_keys.union(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursos Adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Ingestando gran volumen de datos con Python](https://medium.com/towards-artificial-intelligence/efficient-pandas-using-chunksize-for-large-data-sets-c66bf3037f93)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
